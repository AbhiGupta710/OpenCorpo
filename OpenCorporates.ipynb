{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20b47409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class ScrapeOpenCorporates:\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.dic = {\n",
    "            'Website 1':[],\n",
    "            'State':[],\n",
    "            'Keyword':[],\n",
    "            'Status':[],\n",
    "            'Company Name':[],\n",
    "            'Directors / Officers':[]\n",
    "        }\n",
    "        \n",
    "        self.cookies = self.get_cookies_headers()[0]\n",
    "        self.headers = self.get_cookies_headers()[1]\n",
    "        \n",
    "    def get_cookies_headers(self) -> dict:\n",
    "        \n",
    "        cook_head = ''\n",
    "        with open('cookies_headers.txt', 'r') as file:\n",
    "\n",
    "            for i in file.readlines():\n",
    "                cook_head += str(i)\n",
    "        \n",
    "        cookies = dict()\n",
    "        headers = dict()\n",
    "        \n",
    "        if re.search('cookies.=.({.*?})', cook_head, flags=re.S):\n",
    "            \n",
    "            cook = (re.search('cookies.=.({.*?})', cook_head, flags=re.S).group(1))\n",
    "            # remove comments \n",
    "            for i in re.findall('#.\\'.*?\\':.\\'.*?\\',', cook, flags=re.S):\n",
    "                cook = re.sub(i.strip(), '', cook, flags=re.S)\n",
    "\n",
    "            # get headrs and cookies\n",
    "            for i in re.findall('\\'.*?\\':.\\'.*?\\',', cook, flags=re.S):\n",
    "\n",
    "                di_key = i.strip().split(':')[0]\n",
    "                di_val = ':'.join(i.strip().split(':')[1:])\n",
    "                cookies.update({di_key[1:-1]:di_val[2:-2]})\n",
    "                \n",
    "        \n",
    "        if re.search('headers.=.({.*?})', cook_head, flags=re.S):\n",
    "            head = (re.search('headers.=.({.*?})', cook_head, flags=re.S).group(1))\n",
    "            \n",
    "            \n",
    "            # remove comments \n",
    "            for i in re.findall('#.\\'.*?\\':.\\'.*?\\',', head, flags=re.S):\n",
    "                head = re.sub(i.strip(), '', head, flags=re.S)\n",
    "\n",
    "            # get headrs and cookies\n",
    "            for i in re.findall('\\'.*?\\':.\\'.*?\\',', head, flags=re.S):\n",
    "\n",
    "                di_key = i.strip().split(':')[0]\n",
    "                di_val = ':'.join(i.strip().split(':')[1:])\n",
    "                headers.update({di_key[1:-1]:di_val[2:-2]})\n",
    "        \n",
    "        if cookies:\n",
    "            headers.pop('cookie')\n",
    "        \n",
    "        return cookies, headers\n",
    "    \n",
    "    \n",
    "    def leastFactor(self, n):\n",
    "        if (n == 0):\n",
    "            return 0\n",
    "        if (n % 1 or n * n < 2):\n",
    "            return 1\n",
    "        if (n % 2 == 0):\n",
    "            return 2\n",
    "        if (n % 3 == 0):\n",
    "            return 3\n",
    "        if (n % 5 == 0):\n",
    "            return 5\n",
    "\n",
    "        m = int(n ** 0.5)\n",
    "        for i in range(7, m + 1, 30):\n",
    "            if (n % i == 0):\n",
    "                return i\n",
    "            if (n % (i + 4) == 0):\n",
    "                return i + 4\n",
    "            if (n % (i + 6) == 0):\n",
    "                return i + 6\n",
    "            if (n % (i + 10) == 0):\n",
    "                return i + 10\n",
    "            if (n % (i + 12) == 0):\n",
    "                return i + 12\n",
    "            if (n % (i + 16) == 0):\n",
    "                return i + 16\n",
    "            if (n % (i + 22) == 0):\n",
    "                return i + 22\n",
    "            if (n % (i + 24) == 0):\n",
    "                return i + 24\n",
    "\n",
    "        return n\n",
    "\n",
    "    def return_key(self, go_func):\n",
    "        p = eval(re.search('var p=(.*?);', go_func, flags=re.S).group(1).strip())\n",
    "        s = eval(re.search('var s=(.*?);', go_func, flags=re.S).group(1).strip())\n",
    "\n",
    "        n = re.search('var n(.*?);', go_func, flags=re.S).group(1).strip()\n",
    "        n = re.sub('=', '', n)\n",
    "        if re.search('\\d', n):\n",
    "            n = eval(n)\n",
    "\n",
    "        go_func = go_func[re.search('var n(.*?);', go_func, flags=re.S).span()[1]:]\n",
    "        if_block = re.sub('/\\*(.*?)\\*/', '', re.search('if.*?if', go_func, flags=re.S).group(), flags=re.S)\n",
    "        if_block = re.sub('\\n|\\t', '', if_block,flags=re.S)\n",
    "\n",
    "        if ((s >> eval((re.search('s >> (.*?)\\).*&(.*)\\)', if_block).group(1)).strip())) & eval((re.search('s >> (.*?)\\).*&(.*)\\)', if_block).group(2)).strip())):\n",
    "            p += eval(re.search('if.*p.=(.*?);.*?else', if_block).group(1))\n",
    "        else:\n",
    "            p -= eval(re.search('else.*?p.=(.*?);', if_block).group(1))\n",
    "\n",
    "        go_func = go_func[re.search('if.*?if', go_func, flags=re.S).span()[1]-2:]\n",
    "        if_block = re.sub('/\\*(.*?)\\*/', '', re.search('if.*?if', go_func, flags=re.S).group(), flags=re.S)\n",
    "        if_block = re.sub('\\n|\\t', '', if_block,flags=re.S)\n",
    "\n",
    "        if ((s >> eval((re.search('s >> (.*?)\\).*&(.*)\\)', if_block).group(1)).strip())) & eval((re.search('s >> (.*?)\\).*&(.*)\\)', if_block).group(2)).strip())):\n",
    "            p += eval(re.search('if.*p.=(.*?);.*?else', if_block).group(1))\n",
    "        else:\n",
    "            p -= eval(re.search('else.*?p.=(.*?);', if_block).group(1))\n",
    "\n",
    "        go_func = go_func[re.search('if.*?if', go_func, flags=re.S).span()[1]-2:]\n",
    "        if_block = re.sub('/\\*(.*?)\\*/', '', re.search('if.*?if', go_func, flags=re.S).group(), flags=re.S)\n",
    "        if_block = re.sub('\\n|\\t', '', if_block,flags=re.S)\n",
    "\n",
    "        if ((s >> eval((re.search('s >> (.*?)\\).*&(.*)\\)', if_block).group(1)).strip())) & eval((re.search('s >> (.*?)\\).*&(.*)\\)', if_block).group(2)).strip())):\n",
    "            p += eval(re.search('if.*p.=(.*?);.*?else', if_block).group(1))\n",
    "        else:\n",
    "            p -= eval(re.search('else.*?p.=(.*?);', if_block).group(1))\n",
    "\n",
    "        go_func = go_func[re.search('if.*?if', go_func, flags=re.S).span()[1]-2:]\n",
    "        if_block = re.sub('/\\*(.*?)\\*/', '', re.search('if.*?if', go_func, flags=re.S).group(), flags=re.S)\n",
    "        if_block = re.sub('\\n|\\t', '', if_block,flags=re.S)\n",
    "\n",
    "        if ((s >> eval((re.search('s >> (.*?)\\).*&(.*)\\)', if_block).group(1)).strip())) & eval((re.search('s >> (.*?)\\).*&(.*)\\)', if_block).group(2)).strip())):\n",
    "            p += eval(re.search('if.*p.=(.*?);.*?else', if_block).group(1))\n",
    "        else:\n",
    "            p -= eval(re.search('else.*?p.=(.*?);', if_block).group(1))\n",
    "\n",
    "        go_func = go_func[re.search('if.*?if', go_func, flags=re.S).span()[1]-2:]\n",
    "        if_block = re.sub('/\\*(.*?)\\*/', '', re.search('if.*?n=', go_func, flags=re.S).group(), flags=re.S)\n",
    "        if_block = re.sub('\\n|\\t', '', if_block,flags=re.S)\n",
    "\n",
    "        if ((s >> eval((re.search('s >> (.*?)\\).*&(.*)\\)', if_block).group(1)).strip())) & eval((re.search('s >> (.*?)\\).*&(.*)\\)', if_block).group(2)).strip())):\n",
    "            p += eval(re.search('if.*p.=(.*?);.*?else', if_block).group(1))\n",
    "        else:\n",
    "            p -= eval(re.search('else.*?p.=(.*?);', if_block).group(1))\n",
    "\n",
    "        go_func = go_func[re.search('else.*p[\\+|\\-]', go_func, flags=re.S).span()[1]-3:]\n",
    "        sign = re.search('p(.)=', re.search('(.*?);', go_func, flags=re.S).group(1)).group(1)\n",
    "        val = re.search('p.=(.*)', re.search('(.*?);', go_func, flags=re.S).group(1)).group(1)\n",
    "\n",
    "        if sign == '+':\n",
    "            p += eval(val)\n",
    "        else:\n",
    "            p -= eval(val)\n",
    "\n",
    "        n = self.leastFactor(p)\n",
    "\n",
    "        return str(n)+'*' + str(p/n) + ':' + str(s) + re.search('s\\+.(:.*?);', go_func, flags=re.S).group(1)\n",
    "    \n",
    "   \n",
    "    def scrape_companies(self):\n",
    "        \n",
    "        \n",
    "        params = {\n",
    "            'branch': '',\n",
    "            'commit': 'Go',\n",
    "            'mode': 'best_fields',\n",
    "            'nonprofit': '',\n",
    "            'order': 'incorporation_date',\n",
    "            'page': '1',\n",
    "            'q': 'bla',\n",
    "            'search_fields[]': [\n",
    "                'name',\n",
    "                'previous_names',\n",
    "                'company_number',\n",
    "                'other_company_numbers',\n",
    "            ],\n",
    "            'utf8': 'âœ“',\n",
    "        }\n",
    "        \n",
    "        with open('Keywords.txt', 'r') as k:\n",
    "            k = k.read()\n",
    "        keywords = k.split()\n",
    "        \n",
    "        states = input(\"enter the name of the states (comma \\\",\\\"seperated) :- \")\n",
    "        states = states.split(',')\n",
    "        \n",
    "        states_code = [] # code for the given states\n",
    "        \n",
    "        main_page = requests.get('https://opencorporates.com/', headers=self.headers, cookies=self.cookies) # main page\n",
    "        soupm = BeautifulSoup(main_page.content, 'html.parser')\n",
    "        \n",
    "        if soupm.find('script') and re.search('function go\\(\\)', soupm.find('script').text): # if data is not avail update new key\n",
    "            go_func = re.search('function go\\(\\).*', soupm.find('script').text, flags=re.S).group()\n",
    "            cookie_key = self.return_key(go_func)\n",
    "            self.cookies.update({'KEY':cookie_key})\n",
    "            main_page = requests.get('https://opencorporates.com/', headers=self.headers, cookies=self.cookies)\n",
    "            soupm = BeautifulSoup(main_page.content, 'html.parser')\n",
    "            \n",
    "        for state in states:\n",
    "            \n",
    "            for cod in soupm.find('select').find(value='country/us').next_siblings:\n",
    "                if type(cod) == bs4.element.NavigableString:\n",
    "                    continue\n",
    "                if cod.text.strip() == state.strip():\n",
    "                    states_code.append(cod.get('value'))\n",
    "        \n",
    "        counter = 0\n",
    "        for state in states_code:\n",
    "            \n",
    "            self.cookies.update({'jurisdiction_code':state})\n",
    "            for key in keywords:\n",
    "                print('--------', key, '---------------')\n",
    "                for page in range(1, 7+1):\n",
    "                    \n",
    "                    print('++++====== page no:-', page, '======+++++')\n",
    "                    params['q'] = key\n",
    "                    params['page'] = str(page)\n",
    "                    \n",
    "                    response = requests.get(f'https://opencorporates.com/companies/{state}', params=params, cookies=self.cookies, headers=self.headers)\n",
    "                    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                    \n",
    "                    if soup.find('script') and re.search('function go\\(\\)', soup.find('script').text): # if data is not avail update new key\n",
    "                        go_func = re.search('function go\\(\\).*', soup.find('script').text, flags=re.S).group()\n",
    "                        cookie_key = self.return_key(go_func)\n",
    "                        self.cookies.update({'KEY':cookie_key})\n",
    "                        response = requests.get(f'https://opencorporates.com/companies/{state}', params=params, cookies=self.cookies, headers=self.headers)\n",
    "                        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                    \n",
    "                    try:\n",
    "                        for i in soup.find(id='companies').find_all('li'): # all companies at a page\n",
    "\n",
    "                            link = ''\n",
    "                            for li in i.find_all('a'):\n",
    "                                if li.get('href') and re.search(r'/companies/us_.*?/.*', li.get('href')):\n",
    "                                    link = li\n",
    "\n",
    "                            if link == '':\n",
    "                                print('--')\n",
    "                                continue\n",
    "                                \n",
    "                            company_link = 'https://opencorporates.com' + link.get('href')\n",
    "                            comp_name = link.text.strip()\n",
    "                            \n",
    "                            print(comp_name)\n",
    "                            print(company_link)\n",
    "                            \n",
    "                            comp = requests.get(company_link, cookies=self.cookies, headers=self.headers)\n",
    "                            soupc = BeautifulSoup(comp.content, 'html.parser')\n",
    "\n",
    "                            if soupc.find('script') and re.search('function go\\(\\)', soupc.find('script').text): # if data is not avail update new key\n",
    "                                go_func = re.search('function go\\(\\).*', soupc.find('script').text, flags=re.S).group()\n",
    "                                cookie_key = self.return_key(go_func)\n",
    "                                self.cookies.update({'KEY':cookie_key})\n",
    "                                comp = requests.get(company_link, params=params, cookies=self.cookies, headers=self.headers)\n",
    "                                soupc = BeautifulSoup(comp.content, 'html.parser')\n",
    "                            officers = ''\n",
    "                            for i in soupc.find('dd', class_='officers').find_all('li'):\n",
    "                                officers += i.text.strip() +' '\n",
    "                                \n",
    "                            status = soupc.find(class_='status').text\n",
    "                            \n",
    "                            print(f'officers :- {officers}')\n",
    "                            print(f'status :- {status}')\n",
    "                            print('=========')\n",
    "\n",
    "                            self.dic['Website 1'].append(company_link)\n",
    "                            self.dic['State'].append(states[counter])\n",
    "                            self.dic['Keyword'].append(key)\n",
    "                            self.dic['Company Name'].append(comp_name)\n",
    "                            self.dic['Directors / Officers'].append(officers)\n",
    "                            self.dic['Status'].append(status)\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        break\n",
    "            counter += 1\n",
    "    def return_df(self):\n",
    "        return pd.DataFrame(self.dic)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bf7db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = ScrapeOpenCorporates()\n",
    "obj.scrape_companies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87683f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f214c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
